{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BARO's reproducibility\n",
    "\n",
    "In this notebook, we reproduce the effectiveness of BARO on the Online Boutique dataset as presented in Table 3 (The average Avg@5 is **0.86**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import warnings\n",
    "from os.path import join, dirname, basename\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from baro.root_cause_analysis import robust_scorer\n",
    "from baro.utility import load_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg@5 Accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "top1_cnt, top2_cnt, top3_cnt, top4_cnt, top5_cnt, total_cnt = 0, 0, 0, 0, 0, 0\n",
    "\n",
    "for data_path in glob.glob(\"./data/fse-ob/**/simple_data.csv\", recursive=True):\n",
    "    data = pd.read_csv(data_path)\n",
    "    data_dir = os.path.dirname(data_path)\n",
    "    \n",
    "    service, metric = basename(dirname(dirname(data_path))).split(\"_\")\n",
    "    # print(f\"{service=} {metric=}\")\n",
    "    \n",
    "    ############# PREPROCESSING ###############\n",
    "    if \"time.1\" in data:\n",
    "        data = data.drop(columns=[\"time.1\"])\n",
    "    # handle inf\n",
    "    data = data.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # handle na\n",
    "    data = data.ffill()\n",
    "    data = data.fillna(0)\n",
    "    # check if there is any nan or inf\n",
    "    if data.isnull().values.any():\n",
    "        print(f\"{data_path=} has nan\")\n",
    "\n",
    "    if data.isin([np.inf, -np.inf]).values.any():\n",
    "        print(f\"{data_path=} has inf\")\n",
    "    \n",
    "    data = data.loc[:, ~data.columns.str.endswith(\"latency-50\")]\n",
    "    data = data.rename(\n",
    "        columns={\n",
    "            c: c.replace(\"_latency-90\", \"_latency\")\n",
    "            for c in data.columns\n",
    "            if c.endswith(\"_latency-90\")\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # cut data \n",
    "    data_length = 300\n",
    "    with open(join(data_dir, \"inject_time.txt\")) as f:\n",
    "        inject_time = int(f.readlines()[0].strip())\n",
    "    normal_df = data[data[\"time\"] < inject_time].tail(data_length)\n",
    "    anomal_df = data[data[\"time\"] >= inject_time].head(data_length)\n",
    "    data = pd.concat([normal_df, anomal_df], ignore_index=True)    \n",
    "    \n",
    "    ############# READ ANOMALY DETECTION OUTPUT ###############\n",
    "    anomalies = load_json(join(data_dir, \"naive_bocpd.json\"))\n",
    "    anomalies = [i[0] for i in anomalies]    \n",
    "    \n",
    "    ############# ROOT CAUSE ANALYSIS ###############\n",
    "    ranks = robust_scorer(data, anomalies=anomalies)[\"ranks\"]\n",
    "    _service_ranks = [r.split(\"_\")[0] for r in ranks]\n",
    "    service_ranks = []\n",
    "    # remove duplicates\n",
    "    for s in _service_ranks:\n",
    "        if s not in service_ranks:\n",
    "            service_ranks.append(s)\n",
    "    \n",
    "    ############## EVALUATION ###############\n",
    "    if service in service_ranks[:1]:\n",
    "        top1_cnt += 1\n",
    "    if service in service_ranks[:2]:\n",
    "        top2_cnt += 1\n",
    "    if service in service_ranks[:3]:\n",
    "        top3_cnt += 1\n",
    "    if service in service_ranks[:4]:\n",
    "        top4_cnt += 1\n",
    "    if service in service_ranks[:5]:\n",
    "        top5_cnt += 1\n",
    "    total_cnt += 1 \n",
    "    \n",
    "############## EVALUATION ###############    \n",
    "top1_accuracy = top1_cnt / total_cnt\n",
    "top2_accuracy = top2_cnt / total_cnt\n",
    "top3_accuracy = top3_cnt / total_cnt\n",
    "top4_accuracy = top4_cnt / total_cnt\n",
    "top5_accuracy = top5_cnt / total_cnt\n",
    "avg5_accuracy = (top1_accuracy + top2_accuracy + top3_accuracy + top4_accuracy + top5_accuracy) / 5\n",
    "\n",
    "print(f\"Avg@5 Accuracy: {avg5_accuracy}\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
