Metadata-Version: 2.1
Name: wj-google
Version: 0.1.2
Summary: 
Author: Johan
Author-email: mantimanti89@gmail.com
Requires-Python: >=3.11,<4.0
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: black (>=24.2.0,<25.0.0)
Requires-Dist: db-dtypes (>=1.2.0,<2.0.0)
Requires-Dist: flake8 (>=7.0.0,<8.0.0)
Requires-Dist: google (>=3.0.0,<4.0.0)
Requires-Dist: google-api-python-client (>=2.121.0,<3.0.0)
Requires-Dist: google-auth-oauthlib (>=1.2.0,<2.0.0)
Requires-Dist: google-cloud-bigquery (>=3.18.0,<4.0.0)
Requires-Dist: google-cloud-storage (>=2.15.0,<3.0.0)
Requires-Dist: pandas (>=2.2.1,<3.0.0)
Requires-Dist: pytest (>=8.1.1,<9.0.0)
Requires-Dist: python-dotenv (>=1.0.1,<2.0.0)
Description-Content-Type: text/markdown

# wj_google



## Getting started
### Poetry
To make more easy the instalation, is recomended use [Poetry](https://python-poetry.org/docs/), follow the instructions, and then use the command:
```
poetry install
```
To activate the vierual enviroment use:
```
poetry shell
```
### Virtual Enviroment
Or you can use your own virtual enviroment, and install the requirements:
```
python -m venv <env_name>
<env_name>/scripts/activate
pip install -r requirements.txt
```
### Connection to GCP
Is important consult the documentation of GCP, is required obtain the json credentials with the permission to use the resource that is going to use. ***
## Supported services

The currently supported services are:
- Google Drive
- Buckets
- BigQuery (just sql consults)***

### Google Drive
The GCP account must have Google Drive API enabled, and make sure that you have a OAuth 2.0 application created, in Google Cloud console, you can see the [documentation](https://developers.google.com/drive/api/guides/about-sdk?hl=es-419).

The following methods are currently supported:
- Upload files
- Download files
- Create directory
You must The package must be instantiated as follows:
```
from wj_google.google_api.google_api import GoogleApi

googleApi = GoogleApi(
    client_secret_file=CLIENT_SECRET_FILE, -> Json file must be configured in GCP
    api_name=API_NAME, -> drive in this case
    api_version=API_VERSION, -> Current version, 3 in this case
    scopes=GOOGLE_DRIVE_SCOPES, -> Scope of drive see doc
)
```
There are diferent scopes, as you can see in the [documentation](https://developers.google.com/drive/api/guides/api-specific-auth?hl=es-419).

### Google Drive
The GCP account must have Google Drive API enabled, and make sure that you have a OAuth 2.0 application created, in Google Cloud console, you can see the [documentation](https://developers.google.com/drive/api/guides/about-sdk?hl=es-419).

The following methods are currently supported:
- Upload files
- Download files
- Create directory

To use the library, it is necessary to prepare the credentials, and then instantiate the service that will be used.
```
from wj_google.google_api.google_api import GoogleApi

googleApi = GoogleApi(
    client_secret_file=CLIENT_SECRET_FILE, -> Json file must be configured in GCP
    api_name=API_NAME, -> drive in this case
    api_version=API_VERSION, -> Current version, 3 in this case
    scopes=GOOGLE_DRIVE_SCOPES, -> Scope of drive see doc
)
```
There are diferent scopes, as you can see in the [documentation](https://developers.google.com/drive/api/guides/api-specific-auth?hl=es-419).

#### Uploading a file:
```
googleApi.upload_files_to_drive(
    folder_id, -> Id from the drive of the directory 
    file_paths, -> Path of yur file
    mime_types -> Type of file
)
```
#### Downloading a file:
```
googleApi.download_files_drive(
    file_ids -> Google Drive id file, you can find it in the uri
    file_names -> Name given in your local
)
```
#### Creating a directory:
```
googleApi.create_directory_drive(
    directory_name
)
```

### Google storage buckets

This resource can be used with the credentials of a service user, you see de [documentation](https://cloud.google.com/iam/docs/manage-access-service-accounts?hl=es).

The following methods are currently supported:
- Upload files
- Download files
- Create directory

As in the previous case, credentials are required. After which the resource is instantiated.
```
from wj_google.google_cloud.cloud_connector import GoogleStorage
googleStorageClient = GoogleStorage(
    service -> STORAGE in this case and for now***
    credentials
)
```
#### Uploading a file:
```
googleStorageClient.upload_file(
    bucket_name -> Destination bucket 
    source_file_name -> Path of the file to upload
    destination_file_name Name of the file in bucket
)
```
#### Downloading a file:
```
googleStorageClient.download_file(
    bucket_name -> bucket file
    file_name -> name and path in the bucket
    destination_file -> name and path in your local of the file
)
```
#### Creating a bucket:
```
googleStorageClient.create_bucket(
    bucket_name,
    storage_class, -> Optional, to define the type of bucket to use
    location, -> Optional, to define in which region the bucket is hosted 
)
```
#### Listing bucket's files:
```
googleStorageClient.list_files(bucket_name)
```

### Google BigQuery
This resource can be used with the credentials of a service user, you see de [documentation](https://cloud.google.com/python/docs/reference/bigquery/latest).


With the credentials are required. After which the resource is instantiated, in this case just execute the query.
```
from google_cloud.cloud_connector import GoogleBigQuery

bigquery = GoogleBigQuery(
    service=BIGQUERY,
    credentials=GOOGLE_BIGQUEY_CREDENTIALS,
    scopes=scopes -> To use services like Google Drive
)

```
#### Do a consult:

```
query = 'YOUR_SQL_QUERY'
sql_job = bigquery.sql_query(query=query)
```

You can iterate over the sql_job:
```
for item in sql_job:
    print(item.name)
```

#### Add label to bigquery table:

```
labels = {
    "type": "social_media",
    "category": "cloud",
}
bigquery = GoogleBigQuery(service=BIGQUERY, credentials=GOOGLE_BIGQUEY_CREDENTIALS)
bigquery.add_table_labels(
    labels=labels, dataset_name=dataset_name, table_name=table_name
)

```
#### Delete label to bigquery table:
```
delete_labels_in_table(dataset_name, table_name)
```

