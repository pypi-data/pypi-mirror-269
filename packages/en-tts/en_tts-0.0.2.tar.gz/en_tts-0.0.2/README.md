# en-tts

[![PyPI](https://img.shields.io/pypi/v/en-tts.svg)](https://pypi.python.org/pypi/en-tts)
![PyPI](https://img.shields.io/pypi/pyversions/en-tts.svg)
[![Hugging Face ðŸ¤—](https://img.shields.io/badge/%20%F0%9F%A4%97_Hugging_Face-en--tts-blue.svg)](https://huggingface.co/spaces/stefantaubert/en-tts)
[![pytorch](https://img.shields.io/badge/PyTorch_2.0+-ee4c2c?logo=pytorch&logoColor=white)](https://pytorch.org/get-started/pytorch-2.0/)
[![MIT](https://img.shields.io/github/license/stefantaubert/en-tts.svg)](https://github.com/stefantaubert/en-tts/blob/master/LICENSE)
[![PyPI](https://img.shields.io/pypi/wheel/en-tts.svg)](https://pypi.python.org/pypi/en-tts/#files)
![PyPI](https://img.shields.io/pypi/implementation/en-tts.svg)
[![PyPI](https://img.shields.io/github/commits-since/stefantaubert/en-tts/latest/master.svg)](https://github.com/stefantaubert/en-tts/compare/v0.0.2...master)
[![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.11032264.svg)](https://doi.org/10.5281/zenodo.11032264)

Web app, command-line interface and Python library for synthesizing English texts into speech.

## Installation

```sh
pip install en-tts --user
```

## Usage as web app

Visit [ðŸ¤— Hugging Face](https://huggingface.co/spaces/stefantaubert/en-tts) for a live demo.

<a href="https://huggingface.co/spaces/stefantaubert/en-tts">
<img src="https://github.com/stefantaubert/en-tts/raw/master/img/hf.png" alt="Screenshot Hugging Face" style="max-width: 600px; width: 100%"/>
</a>

You can also run it locally be executing `en-tts-web` in CLI and opening your browser on [http://127.0.0.1:7860](http://127.0.0.1:7860).

## Usage as CLI

```sh
en-tts-cli synthesize "When the sunlight strikes raindrops in the air, they act as a prism and form a rainbow."
```

The output can be listened [here](https://github.com/stefantaubert/en-tts/raw/master/examples/rainbow.wav).

## Usage as library

```py
from pathlib import Path
from tempfile import gettempdir

from en_tts import Synthesizer, Transcriber, normalize_audio, save_audio

text = "When the sunlight strikes raindrops in the air, they act as a prism and form a rainbow."

transcriber = Transcriber()
synthesizer = Synthesizer()

text_ipa = transcriber.transcribe_to_ipa(text)
audio = synthesizer.synthesize(text_ipa)

tmp_dir = Path(gettempdir())
save_audio(audio, tmp_dir / "output.wav")

# Optional: normalize output
normalize_audio(tmp_dir / "output.wav", tmp_dir / "output_norm.wav")
```

## Model info

The used TTS model is published [here](https://zenodo.org/records/10107104).

Evaluation results:

- MOS naturalness: 3.55 Â± 0.28 (GT: 4.17 Â± 0.23)
- MOS intelligibility: 4.44 Â± 0.24 (GT: 4.63 Â± 0.19)
- Mean MCD-DTW: 29.15
- Mean penalty: 0.1018

### Phoneme set

- Vowels: i, u, Ã¦, É‘, É”, É™, É›, Éª, ÊŠ, ÊŒ
- Diphthongs: aÉª, aÊŠ, eÉª, oÊŠ, É”Éª
- R-colored vowels: É”r, É™r, É›r, Éªr, ÊŠr, ÊŒr
- Consonants: b, d, dÊ’, f, h, j, k, l, m, n, p, r, s, t, tÊƒ, v, w, z, Ã°, Å‹, É¡, Êƒ, Î¸
- Breaks:
  - SIL0 (no break)
  - SIL1 (short break)
  - SIL2 (break)
  - SIL3 (long break)
- Special characters: . ? ! , : ; - â€” " ' ( ) [ ]

Each vowel, diphthong, r-colored vowel and consonant can have one of these duration markers:

- Ë˜ -> very short, e.g., oÊŠË˜
- nothing -> normal, e.g., oÊŠ
- Ë‘ -> half long, e.g., oÊŠË‘
- Ë -> long, e.g., oÊŠË

Furthermore, each vowel, diphthong and r-colored vowel can have a leading stress symbol attached:

- Ëˆ -> primary stress, e.g., ËˆoÊŠ
- ËŒ -> secondary stress, e.g., ËŒoÊŠ
- nothing -> no stress, e.g., oÊŠ

Stress and duration markers can be combined, e.g., ËŒoÊŠË

## Citation

If you want to cite this repo, you can use the BibTeX-entry generated by GitHub (see *About => Cite this repository*).

- Taubert, S. (2024). en-tts (Version 0.0.2) [Computer software]. [https://doi.org/10.5281/zenodo.11032264](https://doi.org/10.5281/zenodo.11032264)

## Acknowledgments

Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) â€“ Project-ID 416228727 â€“ CRC 1410

The authors gratefully acknowledge the GWK support for funding this project by providing computing time through the Center for Information Services and HPC (ZIH) at TU Dresden.

The authors are grateful to the Center for Information Services and High Performance Computing [Zentrum fur Informationsdienste und Hochleistungsrechnen (ZIH)] at TU Dresden for providing its facilities for high throughput calculations.
