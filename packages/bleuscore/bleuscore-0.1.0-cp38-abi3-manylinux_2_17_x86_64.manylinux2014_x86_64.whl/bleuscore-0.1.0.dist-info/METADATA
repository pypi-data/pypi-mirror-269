Metadata-Version: 2.3
Name: bleuscore
Version: 0.1.0
Classifier: Programming Language :: Rust
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Programming Language :: Python :: Implementation :: PyPy
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Science/Research
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Dist: pytest ; extra == 'test'
Requires-Dist: pytest-sugar ; extra == 'test'
Requires-Dist: hypothesis ; extra == 'test'
Requires-Dist: evaluate ; extra == 'test'
Requires-Dist: black ; extra == 'lint'
Requires-Dist: ruff ~=0.3.7 ; extra == 'lint'
Provides-Extra: test
Provides-Extra: lint
License-File: LICENSE
Summary: A fast bleu score calculator
Keywords: NLP,Tokenizer,BLEU,DeepLearning
Author: Mathew Shen <datahonor@gmail.com>
Author-email: Mathew Shen <datahonor@gmail.com>
License: MIT
Requires-Python: >=3.8
Description-Content-Type: text/markdown; charset=UTF-8; variant=GFM
Project-URL: Homepage, https://github.com/shenxiangzhuang/bleuscore
Project-URL: Source, https://github.com/shenxiangzhuang/bleuscore

# bleuscore

[`bleuscore`](https://github.com/shenxiangzhuang/bleuscore)
is a fast(maybe:) bleu score calculator base on Rust.


## Quick Start
The usage is exactly same with [huggingface evaluate](https://huggingface.co/spaces/evaluate-metric/bleu):

```diff
- import evaluate
+ import bleuscore

predictions = ["hello there general kenobi", "foo bar foobar"]
references = [
    ["hello there general kenobi", "hello there !"],
    ["foo bar foobar"]
]

- bleu = evaluate.load("bleu")
- results = bleu.compute(predictions=predictions, references=references)
+ results = bleuscore.compute(predictions=predictions, references=references)

print(results)
# {'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 
# 'length_ratio': 1.1666666666666667, 'translation_length': 7, 'reference_length': 6}

```

