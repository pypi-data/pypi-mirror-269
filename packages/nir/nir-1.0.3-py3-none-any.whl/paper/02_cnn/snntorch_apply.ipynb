{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import snntorch as snn\n",
    "import numpy as np\n",
    "from snntorch import import_from_nir\n",
    "import nir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['0', '1', '10', '11', '12', '2', '3', '4', '5', '6', '7', '8', '9', 'input', 'output'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = nir.read(\"cnn_sinabs.nir\")\n",
    "graph.nodes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace rnn subgraph with nirgraph\n"
     ]
    }
   ],
   "source": [
    "net = import_from_nir(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphExecutor(\n",
       "  (0): Conv2d(2, 16, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
       "  (1): Leaky()\n",
       "  (10): Leaky()\n",
       "  (11): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (12): Leaky()\n",
       "  (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): Leaky()\n",
       "  (4): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "  (5): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): Leaky()\n",
       "  (7): AvgPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "  (8): Flatten(start_dim=1, end_dim=-1)\n",
       "  (9): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (input): Identity()\n",
       "  (output): Identity()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Spike activity of the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 10, 2, 34, 34])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_data = torch.from_numpy(np.load(\"cnn_numbers.npy\")).float()\n",
    "inp_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = [e.elem for e in net.get_execution_order()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init all I&F neurons\n",
    "mem_dict = {}\n",
    "for idx, module in enumerate(modules):\n",
    "  if isinstance(module, snn.Leaky):\n",
    "    mem_dict[idx] = module.init_leaky()\n",
    "\n",
    "out = []\n",
    "act = []\n",
    "for t in range(inp_data.shape[0]):\n",
    "  x = inp_data[t]\n",
    "  spklayer = None\n",
    "  for idx, module in enumerate(modules):\n",
    "    if isinstance(module, nn.Flatten):\n",
    "      x = x.flatten(1, -1)\n",
    "    elif isinstance(module, snn.Leaky):\n",
    "      x, mem_dict[idx] = module(x, mem_dict[idx])\n",
    "      if spklayer is None:\n",
    "        spklayer = x.detach().numpy()\n",
    "    else:\n",
    "      x = module(x)\n",
    "  out.append(x)\n",
    "  act.append(spklayer)\n",
    "out = torch.stack(out).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 10, 16, 16, 16), (300, 10, 16, 16, 16))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_new = np.array(act)\n",
    "np.save(\"snnTorch_activity.npy\", act_new)\n",
    "act_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Accuracy on the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tonic\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 79/79 [06:56<00:00,  5.28s/it, accuracy=97.85%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 97.85% +/- 1.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bs = 128\n",
    "collate = tonic.collation.PadTensors(batch_first=False)\n",
    "to_frame = tonic.transforms.ToFrame(\n",
    "    sensor_size=tonic.datasets.NMNIST.sensor_size, time_window=1e3\n",
    ")\n",
    "test_ds = tonic.datasets.NMNIST(\"./nmnist\", transform=to_frame, train=False)\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "    test_ds, shuffle=True, batch_size=bs, collate_fn=collate\n",
    ")\n",
    "\n",
    "accuracies = []\n",
    "pbar = tqdm.tqdm(total=len(test_dl), desc=\"Processing\", position=0, leave=True)\n",
    "for idx, (x, y) in enumerate(test_dl):\n",
    "    # x = torch.moveaxis(x, 0, -1)\n",
    "\n",
    "    # reset/init I&F neurons\n",
    "    mem_dict = {}\n",
    "    for idx, module in enumerate(modules):\n",
    "        if isinstance(module, snn.Leaky):\n",
    "            mem_dict[idx] = module.init_leaky()\n",
    "\n",
    "    # forward pass through time\n",
    "    out = []\n",
    "    for t in range(x.shape[0]):\n",
    "        xt = x[t]\n",
    "        for idx, module in enumerate(modules):\n",
    "            if isinstance(module, snn.Leaky):\n",
    "                xt, mem_dict[idx] = module(xt, mem_dict[idx])\n",
    "            elif isinstance(module, nn.Flatten):\n",
    "                xt = xt.flatten(1, -1)\n",
    "            else:\n",
    "                xt = module(xt)\n",
    "        out.append(xt)\n",
    "    out = torch.stack(out).detach()\n",
    "\n",
    "    pred = out.mean(0).argmax(-1)\n",
    "    accuracy = (pred == y).sum() / x.shape[1]\n",
    "    accuracies.append(accuracy)\n",
    "    pbar.set_postfix(accuracy=\"{:.2f}%\".format(sum(accuracies) / len(accuracies) * 100))\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "accuracies = np.array(accuracies)\n",
    "print(f\"accuracy: {accuracies.mean():.2%} +/- {accuracies.std():.2%}\")\n",
    "np.save(\"snntorch_accuracies.npy\", accuracies)\n",
    "np.save(\"snntorch_accuracy.npy\", accuracies.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
