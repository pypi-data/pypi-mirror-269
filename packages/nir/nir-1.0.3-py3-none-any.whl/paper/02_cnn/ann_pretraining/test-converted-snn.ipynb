{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from cnn import CNN\n",
    "from nmnist import NMNISTFrames, NMNISTRaster\n",
    "import sinabs\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the trained CNN and get the validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trainer = pl.Trainer(logger=None)\n",
    "model = CNN.load_from_checkpoint('checkpoints/cnn-step=7030-epoch=04-valid_loss=0.06-valid_acc=0.98.ckpt')\n",
    "# increase num_workers to speed up but caused issues on Mac\n",
    "frames_dataset = NMNISTFrames(save_to='data', batch_size=batch_size, precision=32, num_workers=0)\n",
    "\n",
    "trainer.test(model, frames_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.model.parameters():\n",
    "    print(param.abs().max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we're going to convert the CNN to an SNN and test it on spiking raster data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase num_workers to speed up but caused issues on Mac\n",
    "raster_dataset = NMNISTRaster(save_to='data', batch_size=batch_size, n_time_bins=20, precision=32, num_workers=0)\n",
    "raster_dataset.setup()\n",
    "dataloader = raster_dataset.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn = sinabs.from_torch.from_model(model.model, batch_size=batch_size, add_spiking_output=False).spiking_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sinabs.layers as sl\n",
    "\n",
    "def get_accuracy(model, dataloader, device, flatten_input=False):\n",
    "    model = model.to(device)\n",
    "    predictions = []\n",
    "    for rasters, labels in tqdm(dataloader):\n",
    "        rasters = rasters.to(device)\n",
    "        batch_size = rasters.shape[0]\n",
    "        labels = labels.to(device)\n",
    "        [layer.reset_states() for layer in model.modules() if isinstance(layer, sl.StatefulLayer)]\n",
    "        with torch.no_grad():\n",
    "            if flatten_input: rasters = rasters.flatten(0, 1)\n",
    "            output = model(rasters)\n",
    "            if flatten_input: output = output.unflatten(0, (batch_size, -1))\n",
    "            predictions.append(output.sum(1).argmax(1) == labels)\n",
    "    return torch.cat(predictions).float().mean().item() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(snn, dataloader, device=\"cpu\", flatten_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('synsense')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0d71d32d2b596f460291e0fcc4c5be95d741b16cf87a49532d3e8154ab3bc33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
